# 03.20 📝
## 딥러닝 개요
* Hidden layer를 깊게 쌓음
* 예측 값 Y = bias + W1X1 + ... + WnXn
* 모델이 학습하는 것은 가중치 W의 값
* W의 값을 update하면서 최적의 가중치를 찾는 것
## Perceptron
* 가장 단순한 형태의 신경망
* Hidden Layer가 없이 Single Layer(Input, Output)으로 구성
* 예측 값 계산 -> 실제 값 - 예측값 -> weight update (경사하강법)
## MSE
* 최소의 오류 값
* ![](https://i.imgur.com/L2vsWAU.png)
## 경사하강법
* W 값을 update하면서 오류 값이 최소가 되는 최적의 W를 구하는 방식
* 실제값과 예측값의 차이가 작아지는 방향성으로 보정
## 가중치 update
![](https://raw.githubusercontent.com/chulminkw/CNN_PG/main/utils/images/Weight_update.png)
## Mini-Batch Gradient Descent
* 전체 학습 데이터 중 batch 만큼 임의로 선택하여 계산